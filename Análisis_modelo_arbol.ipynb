{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmy2OoAxzp424xpTXBVccc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peronvidal/tp-grupal-3-marias/blob/master/An%C3%A1lisis_modelo_arbol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoFm6lAIEUNc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "linear_model = LinearRegression()\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import cm\n",
        "import sys\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# sns.set(rc={'figure.figsize':(15,5)})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/peronvidal/tp-grupal-3-marias/raw/master/datasets/intervenciones-de-seguridad-vial/intervenciones-de-seguridad-clean.xlsx"
      ],
      "metadata": {
        "id": "j2s6IF0_Ecep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce65fd73-336e-4409-815a-9d658c8eac48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-11 21:30:49--  https://github.com/peronvidal/tp-grupal-3-marias/raw/master/datasets/intervenciones-de-seguridad-vial/intervenciones-de-seguridad-clean.xlsx\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/peronvidal/tp-grupal-3-marias/master/datasets/intervenciones-de-seguridad-vial/intervenciones-de-seguridad-clean.xlsx [following]\n",
            "--2023-06-11 21:30:49--  https://raw.githubusercontent.com/peronvidal/tp-grupal-3-marias/master/datasets/intervenciones-de-seguridad-vial/intervenciones-de-seguridad-clean.xlsx\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 495977 (484K) [application/octet-stream]\n",
            "Saving to: ‘intervenciones-de-seguridad-clean.xlsx.4’\n",
            "\n",
            "intervenciones-de-s 100%[===================>] 484.35K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-06-11 21:30:49 (13.3 MB/s) - ‘intervenciones-de-seguridad-clean.xlsx.4’ saved [495977/495977]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('intervenciones-de-seguridad-clean.xlsx')"
      ],
      "metadata": {
        "id": "esPvo0iYEhWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Aca se agregan columnas con datos relacionados a fechas\n",
        "df['fecha_original'] = df['fecha']\n",
        "df['fecha'] = pd.to_datetime(df['fecha']) # todas las fechas a datetime de pandas\n",
        "df['year'] = pd.DatetimeIndex(df['fecha']).year\n",
        "df['month'] = pd.DatetimeIndex(df['fecha']).month\n",
        "df['day'] = pd.DatetimeIndex(df['fecha']).month\n",
        "# Define a function to apply the condition\n",
        "def condition(row):\n",
        "    if row['lesionados'] > 0 or row['fallecidos']>0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Apply the function to create a new column\n",
        "# df['NewColumn'] = df.apply(lambda row: condition(row), axis=1)\n",
        "\n",
        "df['heridos_o_fallecidos'] = df.apply(lambda row: condition(row), axis=1)\n",
        "df.loc[df['moto'] > 0, 'moto'] = 1\n",
        "df.loc[df['liviano'] > 0, 'liviano'] = 1\n",
        "df.loc[df['bus'] > 0, 'bus'] = 1\n",
        "df.loc[df['camion'] > 0, 'camion'] = 1"
      ],
      "metadata": {
        "id": "1UnsOxtuEk6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = pd.get_dummies(data=df, columns=['condiciones_meteorologicas','autopista','superficie_de_la_via','moto','liviano','camion','bus'])\n",
        "X = pd.concat([X,df[['month','day']]],axis=1)\n",
        "y = df['heridos_o_fallecidos']\n",
        "X = X.drop([\"heridos_o_fallecidos\",\"fecha\",\"pk\",\"banda_y_o_ramal\",\"lesionados\",\"fallecidos\",\"year\",\"fecha\",\"tipo_de_siniestro\",\"hora\",\"fecha_original\"], axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42)\n",
        "# bolsa de sueños: una forma mas facil de conseguir solo los dummies"
      ],
      "metadata": {
        "id": "QcgHdkXvErFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None] + list(range(1, 21)),\n",
        "    'min_samples_split': [2, 5, 10, 15, 20],\n",
        "    'min_samples_leaf': [1, 2, 4, 8, 16]\n",
        "}\n",
        "\n",
        "# Create a decision tree classifier object\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Create a KFold object for cross-validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=kfold)\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best Parameters: \", grid_search.best_params_)\n",
        "print(\"Best Score: \", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS2wzHrrAl7L",
        "outputId": "780a57bf-41af-4955-e827-4ae337ab2055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters:  {'criterion': 'gini', 'max_depth': 1, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "Best Score:  0.7618348200440648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "clf = DecisionTreeClassifier(criterion='gini',max_depth=1, min_samples_leaf=1, min_samples_split=2)\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Exactitud:\", accuracy)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "print(\"Matriz de confusión:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print(\"Precisión:\", precision)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print(\"Exhaustividad:\", recall)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"Valor-F:\", f1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TmtJzdnA_Uv",
        "outputId": "8a568d86-951e-4e60-e66f-d50b15f6aa7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exactitud: 0.7598971722365039\n",
            "Matriz de confusión:\n",
            "[[965 141]\n",
            " [326 513]]\n",
            "Precisión: 0.7844036697247706\n",
            "Exhaustividad: 0.6114421930870083\n",
            "Valor-F: 0.6872069658405894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "# Crear el pipeline con los pasos de preprocesamiento y el modelo\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessing', StandardScaler()),  # Paso de preprocesamiento: escalamiento de características\n",
        "    ('model', DecisionTreeClassifier(criterion='gini',max_depth=1, min_samples_leaf=1, min_samples_split=2))  # Paso del modelo: Regresión Logística\n",
        "])\n",
        "\n",
        "# Realizar la validación cruzada con el pipeline\n",
        "accuracy = cross_val_score(pipeline, X, y, cv=10, scoring='accuracy')\n",
        "recall =cross_val_score(pipeline, X, y, cv=10, scoring='recall')\n",
        "# Imprimir los resultados de la validación cruzada\n",
        "print(\"Scores de validación cruzada:\", accuracy)\n",
        "print(\"Promedio del score accuracy:\", accuracy.mean())\n",
        "print(\"Scores de validación cruzada:\", recall)\n",
        "print(\"Promedio del score recall:\", recall.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GbQ2FZvXn9J",
        "outputId": "3d23af96-85b8-4366-b633-a5af6992c291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores de validación cruzada: [0.74935733 0.77506427 0.7622108  0.70051414 0.75192802 0.7403599\n",
            " 0.77763496 0.81209781 0.79279279 0.75160875]\n",
            "Promedio del score accuracy: 0.7613568765239715\n",
            "Scores de validación cruzada: [0.55855856 0.64156627 0.63253012 0.54216867 0.68072289 0.67771084\n",
            " 0.7560241  0.70783133 0.60843373 0.55421687]\n",
            "Promedio del score recall: 0.6359763377835665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "34d2auaia1c0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}