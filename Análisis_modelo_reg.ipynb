{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peronvidal/tp-grupal-3-marias/blob/master/An%C3%A1lisis_modelo_arbol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GoFm6lAIEUNc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import cm\n",
        "# import grid searchcv\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import sys\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalar paquetes en entorno virtual\n",
        "# import sys\n",
        "# !{sys.executable} -m pip install pandas matplotlib scikit-learn seaborn numpy openpyxl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2s6IF0_Ecep",
        "outputId": "ce65fd73-336e-4409-815a-9d658c8eac48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-06-15 17:02:30--  ftp://https/\n",
            "           => ‘.listing’\n",
            "Resolving https (https)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘https’\n",
            "//: Scheme missing.\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2023-06-15 17:02:30--  https://github.com/peronvidal/tp-grupal-3-marias/raw/master/datasets/intervenciones-de-seguridad-vial/intervenciones-de-seguridad-clean.xlsx\n",
            "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
            "Resolving github.com (github.com)... 20.201.28.151\n",
            "Connecting to github.com (github.com)|20.201.28.151|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/peronvidal/tp-grupal-3-marias/master/datasets/intervenciones-de-seguridad-vial/intervenciones-de-seguridad-clean.xlsx [following]\n",
            "--2023-06-15 17:02:31--  https://raw.githubusercontent.com/peronvidal/tp-grupal-3-marias/master/datasets/intervenciones-de-seguridad-vial/intervenciones-de-seguridad-clean.xlsx\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 495977 (484K) [application/octet-stream]\n",
            "Saving to: ‘intervenciones-de-seguridad-clean.xlsx.2’\n",
            "\n",
            "intervenciones-de-s 100%[===================>] 484,35K  --.-KB/s    in 0,06s   \n",
            "\n",
            "2023-06-15 17:02:31 (7,99 MB/s) - ‘intervenciones-de-seguridad-clean.xlsx.2’ saved [495977/495977]\n",
            "\n",
            "FINISHED --2023-06-15 17:02:31--\n",
            "Total wall clock time: 1,0s\n",
            "Downloaded: 1 files, 484K in 0,06s (7,99 MB/s)\n"
          ]
        }
      ],
      "source": [
        "!wget https: // github.com/peronvidal/tp-grupal-3-marias/raw/master/datasets/intervenciones-de-seguridad-vial/intervenciones-de-seguridad-clean.xlsx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "esPvo0iYEhWD"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('intervenciones-de-seguridad-clean.xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1UnsOxtuEk6w"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Aca se agregan columnas con datos relacionados a fechas\n",
        "df['fecha_original'] = df['fecha']\n",
        "# todas las fechas a datetime de pandas\n",
        "df['fecha'] = pd.to_datetime(df['fecha'])\n",
        "df['year'] = pd.DatetimeIndex(df['fecha']).year\n",
        "df['month'] = pd.DatetimeIndex(df['fecha']).month\n",
        "df['day'] = pd.DatetimeIndex(df['fecha']).day_of_week\n",
        "# Define a function to apply the condition\n",
        "\n",
        "\n",
        "def condition(row):\n",
        "    if row['lesionados'] > 0 or row['fallecidos'] > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def is_weekend(row):\n",
        "    # incluye el viernes\n",
        "    if pd.to_datetime(row['fecha']).day_of_week >= 5:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "    \n",
        "# Apply the function to create a new column\n",
        "# df['NewColumn'] = df.apply(lambda row: condition(row), axis=1)\n",
        "\n",
        "\n",
        "df['heridos_o_fallecidos'] = df.apply(lambda row: condition(row), axis=1)\n",
        "df.loc[df['moto'] > 0, 'moto'] = 1\n",
        "df.loc[df['liviano'] > 0, 'liviano'] = 1\n",
        "df.loc[df['bus'] > 0, 'bus'] = 1\n",
        "df.loc[df['camion'] > 0, 'camion'] = 1\n",
        "df['fin_de_semana'] = df.apply(lambda row: is_weekend(row), axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QcgHdkXvErFx"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = pd.get_dummies(data=df, columns=['condiciones_meteorologicas', 'autopista',\n",
        "                   'superficie_de_la_via', 'moto', 'liviano', 'camion', 'bus','month', 'day','fin_de_semana','banda_y_o_ramal'])\n",
        "# X = pd.concat([X, df[['month', 'day','fin_de_semana']]], axis=1)\n",
        "y = df['heridos_o_fallecidos']\n",
        "X = X.drop([\"heridos_o_fallecidos\", \"fecha\", \"lesionados\",\n",
        "           \"fallecidos\", \"year\", \"fecha\", \"tipo_de_siniestro\", \"hora\", \"fecha_original\",\"pk\"], axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42)\n",
        "# bolsa de sueños: una forma mas facil de conseguir solo los dummies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS2wzHrrAl7L",
        "outputId": "780a57bf-41af-4955-e827-4ae337ab2055"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Aca se define el modelo y su grilla de parametros\n",
        "# El resto del notebook deberia funcionar con cualquier tipo de modelo con su grilla respectiva\n",
        "\n",
        "# Define the parameter grid\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# PARAM GRID AND MODEL FOR SGDClassifier\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'loss': ['hinge', 'log_loss', 'modified_huber'],\n",
        "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'max_iter': [1000, 2000, 3000],\n",
        "    'tol': [1e-3, 1e-4, 1e-5],\n",
        "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
        "    'eta0': [0.1, 0.01, 0.001],\n",
        "    'power_t': [0.1, 0.5, 1.0],\n",
        "    'early_stopping': [True, False],\n",
        "    'validation_fraction': [0.1, 0.2, 0.3],\n",
        "    'n_iter_no_change': [5, 10, 15],\n",
        "    'warm_start': [True, False],\n",
        "    'average': [True, False]\n",
        "}\n",
        "\n",
        "# Create the SGDClassifier\n",
        "clf = SGDClassifier()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SE DEFINEN LAS METRICAS A UTILIZAR EN EL GRID SEARCH\n",
        "scorers = {\n",
        "    'precision_score': make_scorer(precision_score,zero_division=1.0),\n",
        "    'recall_score': make_scorer(recall_score,zero_division=1.0),\n",
        "    'accuracy_score': make_scorer(accuracy_score,zero_division=1.0),\n",
        "    'f1_score': make_scorer(f1_score,zero_division=1.0)\n",
        "}\n",
        "\n",
        "# Funcion para realizar el grid search, se puede cambiar el parametro cv si es muy lento\n",
        "# todo para version definitiva deberia considerarse un cv mas alto\n",
        "def grid_search_wrapper(refit_score='precision_score'):\n",
        "    \"\"\"\n",
        "    fits a GridSearchCV classifier using refit_score for optimization\n",
        "    prints classifier performance metrics\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Determine the number of CPU cores available\n",
        "    \n",
        "    grid_search = GridSearchCV(clf, param_grid, scoring=scorers, refit=refit_score,\n",
        "                               cv=4, return_train_score=True, n_jobs=-1)\n",
        "    grid_search.fit(X_train.values, y_train.values)\n",
        "    y_pred = grid_search.predict(X_test.values)\n",
        "    \n",
        "    print('Best params for {}'.format(refit_score))\n",
        "    print(grid_search.best_params_)\n",
        "    \n",
        "    # print score for test set\n",
        "    print('Best score for {}'.format(refit_score))  \n",
        "    print(grid_search.best_score_)\n",
        "    \n",
        "    \n",
        "\n",
        "    # confusion matrix on the test data.\n",
        "    # loop over scorers key names\n",
        "    print('\\nConfusion matrix of classifier optimized for {} on the test data:'.format(\n",
        "        refit_score))\n",
        "    print(pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
        "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
        "    print('\\n')\n",
        "    \n",
        "\n",
        "    return grid_search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se realiza el grid search para cada una de las metricas\n",
        "# El refit es la metrica que se utiliza para elegir el mejor modelo\n",
        "# create a dicctionary of grid_search classifiers for each scorer key name1\n",
        "grid_searches = {}\n",
        "for score in scorers:\n",
        "    grid_searches[score] = grid_search_wrapper(refit_score=score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# guardo los modelos en un archivo\n",
        "import joblib\n",
        "joblib.dump(grid_searches, 'super_regclassifier.pkl')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set(rc={'figure.figsize': (5, 5)})\n",
        "\n",
        "metrica_ = 'recall_score'\n",
        "\n",
        "y_pred_arbol = grid_searches[f'{metrica_}'].predict(X)\n",
        "cf_matrix = confusion_matrix(y, y_pred_arbol)\n",
        "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
        "group_counts = ['{0:0.0f}'.format(value) for value in\n",
        "                cf_matrix.flatten()]\n",
        "group_percentages = ['{0:.2%}'.format(value) for value in\n",
        "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
        "          zip(group_names, group_counts, group_percentages)]\n",
        "labels = np.asarray(labels).reshape(2, 2)\n",
        "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
        "# add title\n",
        "plt.title(f'Matriz de confusion proprizando {metrica_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = pd.DataFrame(grid_searches['precision_score'].cv_results_)\n",
        "results = results.sort_values(by='mean_test_recall_score', ascending=False)\n",
        "# se tienen en cuenta las medianas de cada metrica y ordenar por la metrica que se quiere optimizar\n",
        "# Decision Tree Parameters\n",
        "\n",
        "\n",
        "\n",
        "# SGD CLASSIFIER PARAMETERS\n",
        "results[[\n",
        "    'mean_test_precision_score', 'mean_test_recall_score', 'mean_test_accuracy_score', 'mean_test_f1_score', 'param_loss', 'param_penalty', 'param_alpha', 'param_max_iter', 'param_tol'\n",
        "\n",
        "    # ,'param_max_features'\n",
        "    # ,'param_n_estimators'\n",
        "]]\n",
        "\n",
        "# export results of dataframe in csv\n",
        "# .to_csv('results.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sirve para graficar recall y precision vs threshold\n",
        "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.title(\"Precision and Recall Scores as a function of the decision threshold\")\n",
        "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
        "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.xlabel(\"Decision Threshold\")\n",
        "    plt.legend(loc='best')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Precision = TP / (TP + FP)\n",
        "# Recall = TP / (TP + FN) (True positive rate)\n",
        "# FIXME:UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
        "# warnings.warn( TIRA ESTE ERROR POR QUE SON FEATURES CON HOTE ENCODING.\n",
        "y_scores = grid_searches['precision_score'].predict_proba(X_test)[:, 1]\n",
        "p, r, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "plot_precision_recall_vs_threshold(p, r, thresholds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Precision = TP / (TP + FP)\n",
        "# Recall = TP / (TP + FN) (True positive rate)\n",
        "# FIXME:UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
        "# warnings.warn( TIRA ESTE ERROR POR QUE SON FEATURES CON HOTE ENCODING\n",
        "y_scores = grid_searches['recall_score'].predict_proba(X_test)[:, 1]\n",
        "p, r, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "plot_precision_recall_vs_threshold(p, r, thresholds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_roc_curve(fpr, tpr, label=None):\n",
        "    \"\"\"\n",
        "    The ROC curve, modified from \n",
        "    Hands-On Machine learning with Scikit-Learn and TensorFlow; p.91\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.title('ROC Curve')\n",
        "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
        "    # get random number between 0 and 1\n",
        "    r = np.random.rand()\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.axis([-0.005, 1, 0, 1.005])\n",
        "    plt.xticks(np.arange(0, 1, 0.05), rotation=90)\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate (Recall)\")\n",
        "    plt.legend(loc='best')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# roc curve sirve para graficar recall en funcion de false positive rate y true positive rate\n",
        "# La curva ROC(Receiver Operating Characteristic) es una representación gráfica que muestra la relación\n",
        "# entre la tasa de verdaderos positivos(TPR) y la tasa de falsos positivos(FPR) al variar el umbral de clasificación del modelo.\n",
        "# El AUC(Area Under the Curve) es el área bajo la curva ROC y proporciona una medida numérica de la calidad global del modelo de clasificación.\n",
        "# El AUC varía entre 0 y 1, donde un AUC de 1 indica un modelo perfecto y un AUC de 0.5 indica rendimiento similar al azar.\n",
        "y_scores = grid_searches['recall_score'].predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, auc_thresholds = roc_curve(y_test, y_scores)\n",
        "print(auc(fpr, tpr))  # AUC of ROC\n",
        "plot_roc_curve(fpr, tpr, 'recall_optimized')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "sns.set(rc={'figure.figsize': (10, 5)})\n",
        "\n",
        "\n",
        "# importances with SGD\n",
        "importances = np.abs(grid_searches['recall_score'].best_estimator_.coef_)[0]\n",
        "\n",
        "# Importances with deccision tree\n",
        "# importances = grid_searches['recall_score'].best_estimator_.feature_importances_\n",
        "\n",
        "\n",
        "columns = X.columns\n",
        "# reorder importances and columns variables so that they are sorted in descending order of importance\n",
        "indices = np.argsort(importances)[::-1]\n",
        "names = [columns[i] for i in indices]\n",
        "# reorder list using a list of indices\n",
        "importances = [importances[i] for i in indices]\n",
        "columns = [columns[i] for i in indices]\n",
        "\n",
        "# slice indices and importances after position 16\n",
        "max_features = 15\n",
        "columns = names[:max_features]\n",
        "importances = importances[:max_features]\n",
        "# print()\n",
        "\n",
        "ax = sns.barplot(y=columns, x=importances, width=1)\n",
        "plt.title('Importancia de cada Feature Para determinar si en un accidente hubo heridos/fallecidos o no')\n",
        "# plt.xscale('log')\n",
        "# xticks=ax.yaxis.get_major_ticks()\n",
        "# for i in range(len(xticks)):\n",
        "#     if i%2==1:\n",
        "#         xticks[i].set_visible(False)\n",
        "# plt.gca().invert_xaxis()\n",
        "plt.show()\n",
        "# revert axis\n",
        "# set y axis in log scale\n",
        "\n",
        "# get feature weights with its name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# clf.weights = grid_search_clf_tree.best_estimator_.feature_importances_\n",
        "# get clf weights with feature names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # plot distribution of probabilities of a class\n",
        "# plt.figure(figsize=(8, 8))\n",
        "# plt.title('Distribution of probabilities of a class')\n",
        "# plt.hist(y_scores, bins=10)\n",
        "# plt.xlim(0, 1)\n",
        "# plt.xlabel('Probability of a class')\n",
        "# plt.ylabel('Number of occurrences')\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # plot locations of streets on the dataset using street name and number in argentina buenos aires map\n",
        "# # https://www.google.com/maps/d/u/0/viewer?mid=1Q4Q1Z4Z1ZQ1Z4Z1Q4&ll=-34.60372200000001%2C-58.38159299999999&z=12\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPmy2OoAxzp424xpTXBVccc",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
